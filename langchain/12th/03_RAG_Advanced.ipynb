{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[API KEY]\n",
      "sk-None-FZcW7iODyxjiAh7qYSpIT3BlbkFJyqnfN***************\n",
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "yong_12\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_teddynote import logging\n",
    "print(load_dotenv())\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)\n",
    "logging.langsmith(\"yong_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 Question-Answering 챗봇입니다. 주어진 질문에 대한 답변을 제공해주세요.\",\n",
    "        ),\n",
    "        # 대화기록용 key 인 chat_history 는 가급적 변경 없이 사용하세요!\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"#Question:\\n{question}\"),  # 사용자 입력을 변수로 사용\n",
    "\n",
    "            ]\n",
    ")\n",
    "# llm 생성\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 일반 Chain 생성\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "# 세션 id를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_history(session_ids):\n",
    "    print(f'[대화 세션ID] : {session_ids}')\n",
    "    if session_ids not in store:\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_history,\n",
    "    input_messages_key='question',\n",
    "    history_messages_key='chat_history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID] : abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋아하는 것을 가지고 즐기는 것은 좋은 일이에요! 주지육림은 맛있는 음식이죠. 한용이에게 주지육림을 주는 것은 좋은 아이디어일 것 같아요. 함께 맛있는 식사를 즐기는 시간이 되기를 바라요.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    {\"question\": \"나는 한용이야 내가 좋아하는 것은 주지육림이야\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID] : abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신이 좋아하는 것은 주지육림이라고 말씀하셨어요! 주지육림을 좋아한다니 멋진 취향이네요. 맛있는 한 끼 식사를 즐기는 것은 행복한 일이죠. 함께 좋아하는 것들을 찾아 즐기는 시간이 되길 바라요.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"내가 좋아하는게 뭐라고?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFPlumberLoader(\"data/Statistics 11th Edition_240709_201017.pdf\")\n",
    "docs = loader.load()\n",
    "# 문서분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "# 임베딩\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# db생성\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "# 검색기 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "# 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Previous Chat History:\n",
    "{chat_history}\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "# llm생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "# 체인 생성\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID] : rag123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'t-test의 종류는 다음과 같습니다:\\n\\n1. 단일 표본 t-test (t for one sample)\\n2. 두 독립 표본 t-test (t for two independent samples)\\n3. 두 관련 표본 t-test (t for two related samples)\\n\\n이 세 가지 종류의 t-test는 각각의 연구 상황에 따라 적절하게 선택되어 사용됩니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = {}\n",
    "\n",
    "# 세션 id를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_history(session_ids):\n",
    "    print(f'[대화 세션ID] : {session_ids}')\n",
    "    if session_ids not in store:\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_history,\n",
    "    input_messages_key='question',\n",
    "    history_messages_key='chat_history'\n",
    ")\n",
    "\n",
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"ttest의 종류는?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"rag123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID] : rag123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The types of t-tests are as follows:\\n\\n1. One-sample t-test\\n2. Two independent samples t-test\\n3. Two related samples t-test\\n\\nThese three types of t-tests are appropriately selected and used depending on the research situation.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"이전 답변을 영어로 번역해주세요.\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"rag123\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
