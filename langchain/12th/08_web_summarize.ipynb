{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[API KEY]\n",
      "sk-None-FZcW7iODyxjiAh7qYSpIT3BlbkFJyqnfN***************\n",
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "yong_12\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_teddynote import logging\n",
    "print(load_dotenv())\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)\n",
    "logging.langsmith(\"yong_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import textwrap\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Load some data to summarize\n",
    "loader = WebBaseLoader(\"https://teddylee777.github.io/data-science/optuna/\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "\n",
    "# Get this prompt template\n",
    "prompt = hub.pull(\"lawwu/chain_of_density\")\n",
    "\n",
    "# The chat model output is a JSON list of dicts, with SimpleJsonOutputParser\n",
    "# we can convert it o a dict, and it suppors streaming.\n",
    "json_parser = SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"ARTICLE\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n",
    "    | json_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Missing_Entities': 'Optuna',\n",
       "  'Denser_Summary': 'This article discusses Optuna, a hyperparameter optimization library for machine learning. Optuna provides a simple and efficient way to search for the best hyperparameters for a given model. It uses a variety of search algorithms to explore the hyperparameter space and find the optimal values. With Optuna, you can easily tune the hyperparameters of your machine learning models and improve their performance.'},\n",
       " {'Missing_Entities': 'trial.suggest_categorical()',\n",
       "  'Denser_Summary': 'Optuna provides a wide range of functions to suggest hyperparameters, including trial.suggest_categorical(). This function allows you to specify a categorical parameter and its possible choices. Optuna will then explore the different choices and find the best one for your model. By using trial.suggest_categorical(), you can easily optimize categorical hyperparameters and improve the performance of your machine learning models.'},\n",
       " {'Missing_Entities': 'trial.suggest_int()',\n",
       "  'Denser_Summary': 'Another useful function provided by Optuna is trial.suggest_int(). This function allows you to specify an integer parameter and its range of possible values. Optuna will then search for the best integer value within the specified range. By using trial.suggest_int(), you can optimize integer hyperparameters and find the optimal values for your machine learning models.'},\n",
       " {'Missing_Entities': 'trial.suggest_float()',\n",
       "  'Denser_Summary': 'In addition to categorical and integer hyperparameters, Optuna also supports floating-point hyperparameters. You can use the trial.suggest_float() function to specify a floating-point parameter and its range of possible values. Optuna will then search for the best floating-point value within the specified range. By using trial.suggest_float(), you can optimize floating-point hyperparameters and improve the performance of your machine learning models.'},\n",
       " {'Missing_Entities': 'objective function',\n",
       "  'Denser_Summary': 'The objective function is a key component of using Optuna for hyperparameter optimization. It defines the evaluation metric that Optuna will use to assess the performance of different hyperparameter configurations. By defining a suitable objective function, you can guide Optuna to find the best hyperparameters for your machine learning models. The objective function takes the trial object, the model, the input data, the target data, and the evaluation metric as inputs. It returns the error or loss value that Optuna will minimize during the optimization process.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"\",\n",
      "        \"Denser_Summary\": \"이 기사는 데이터사이언스, 머신러닝, 인공지능에 대한 개념을 설명하고 있습니다. 박정현 서울대 EPM 연구원이 작성한 이 글은 이러한 기술들이 우리 생활에 어떻게 적용되고 있는지, 그리고 이 분야를 공부하고자 하는 사람들에게 어떤 조언을 할 수 있는지에 대해 다루고 있습니다. 또한, 데이터사이언스가 가장 넓은 범위를 가지고 있으며, 머신러닝과 인공지능이 어떻게 서로 관련되어 있는지에 대해서도 설명하고 있습니다. 이 글은 이 분야에 대한 기본적인 이해를 돕기 위해 여러 가지 예시와 함께 이론적, 실용적 측면에서 접근하고 있습니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"데이터사이언스 대학원; 인공지능 국가전략; 튜링테스트\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 개념과 실생활 적용 예를 설명합니다. 데이터사이언스가 가장 넓은 범위를 가지며, 여러 대학에서 데이터사이언스 대학원을 설립하고, 인공지능 국가전략이 발표됨을 언급합니다. 머신러닝과 인공지능의 관계, 튜링테스트를 통한 인공지능의 이해 방법도 다룹니다. 이 글은 이론적, 실용적 측면에서 이 분야에 대한 기본적인 이해를 돕고자 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"지도학습; 비지도 학습; 클러스터링\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 적용을 설명하며, 데이터사이언스 대학원 설립, 인공지능 국가전략 발표를 언급합니다. 머신러닝의 지도학습, 비지도 학습, 클러스터링 방법론과 튜링테스트를 통한 인공지능 이해를 다룹니다. 이 글은 이론적, 실용적 측면에서 이 분야의 기본적인 이해를 목표로 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"데이터 피처 엔지니어링; 알고리즘; 성능평가\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 적용, 데이터사이언스 대학원 설립, 인공지능 국가전략 발표를 소개합니다. 머신러닝의 지도학습, 비지도 학습, 클러스터링, 데이터 피처 엔지니어링, 알고리즘, 성능평가 방법론과 튜링테스트를 통한 인공지능 이해를 다룹니다. 이 글은 이론적, 실용적 측면에서 이 분야의 기본적인 이해를 목표로 합니다.\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"회귀; 분류\",\n",
      "        \"Denser_Summary\": \"박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 적용, 데이터사이언스 대학원 설립, 인공지능 국가전략 발표를 소개합니다. 머신러닝의 지도학습, 비지도 학습, 클러스터링, 데이터 피처 엔지니어링, 알고리즘(회귀, 분류 포함), 성능평가 방법론과 튜링테스트를 통한 인공지능 이해를 다룹니다. 이 글은 이론적, 실용적 측면에서 이 분야의 기본적인 이해를 목표로 합니다.\"\n",
      "    }\n",
      "]\n",
      "```박정현 서울대 EPM 연구원은 데이터사이언스, 머신러닝, 인공지능의 정의와 적용, 데이터사이언스 대학원 설립, 인공지능 국가전략 발표를 소개합니다. 머신러닝의 지도학습, 비지도 학습, 클러스터링, 데이터 피처 엔지니어링, 알고리즘(회귀, 분류 포함), 성능평가 방법론과 튜링테스트를 통한 인공지능 이해를 다룹니다. 이 글은 이론적, 실용적 측면에서 이 분야의 기본적인 이해를 목표로 합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import json\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://www.aitimes.com/news/articleView.html?idxno=131777\")\n",
    "docs = loader.load()\n",
    "content = docs[0].page_content\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Article: {ARTICLE}\n",
    "You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "Repeat the following 2 steps 5 times. \n",
    "\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "A missing entity is:\n",
    "- relevant to the main story, \n",
    "- specific yet concise (50 words or fewer), \n",
    "- novel (not in the previous summary), \n",
    "- faithful (present in the article), \n",
    "- anywhere (can be located anywhere in the article).\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "Use only KOREAN language to reply.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the chain, including\n",
    "chain = (\n",
    "    prompt\n",
    "    | ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        streaming=True,\n",
    "        callbacks=[StreamCallback()],\n",
    "    )\n",
    "    | JsonOutputParser()\n",
    "    | (lambda x: x[-1][\"Denser_Summary\"])\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke({\"ARTICLE\": content})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
