{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain umap-learn scikit-learn langchain_community tiktoken langchain-openai langchainhub chromadb langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    # 주어진 문자열에서 토큰의 개수를 반환합니다.\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "# LCEL 문서 로드\n",
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# PydanticOutputParser를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_pydantic = loader.load()\n",
    "\n",
    "# Self Query를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_sq = loader.load()\n",
    "\n",
    "# 문서 텍스트\n",
    "docs.extend([*docs_pydantic, *docs_sq])\n",
    "docs_texts = [d.page_content for d in docs]\n",
    "\n",
    "# 각 문서에 대한 토큰 수 계산\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in docs_texts]\n",
    "\n",
    "# 토큰 수의 히스토그램을 그립니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Token Counts in LCEL Documents\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "# 히스토그램을 표시합니다.\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 5175\n"
     ]
    }
   ],
   "source": [
    "# 문서 텍스트를 연결합니다.\n",
    "# 문서를 출처 메타데이터 기준으로 정렬합니다.\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))  # 정렬된 문서를 역순으로 배열합니다.\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [\n",
    "        # 역순으로 배열된 문서의 내용을 연결합니다.\n",
    "        doc.page_content\n",
    "        for doc in d_reversed\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Num tokens in all context: %s\"  # 모든 문맥에서의 토큰 수를 출력합니다.\n",
    "    % num_tokens_from_string(concatenated_content, \"cl100k_base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할을 위한 코드\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size_tok = 2000  # 토큰의 청크 크기를 설정합니다.\n",
    "# 재귀적 문자 텍스트 분할기를 초기화합니다. 토큰 인코더를 사용하여 청크 크기와 중복을 설정합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size_tok, chunk_overlap=0\n",
    ")\n",
    "texts_split = text_splitter.split_text(\n",
    "    concatenated_content\n",
    ")  # 주어진 텍스트를 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[API KEY]\n",
      "sk-None-FZcW7iODyxjiAh7qYSpIT3BlbkFJyqnfN***************\n",
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "yong_12\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_teddynote import logging\n",
    "print(load_dotenv())\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)\n",
    "logging.langsmith(\"yong_12\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "# embeddings 인스턴스를 생성합니다.\n",
    "embd = OpenAIEmbeddings(model=\"text-embedding-3-small\", disallowed_special=())\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embd, store, namespace=embd.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "class StreamCallback(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs):\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamCallback()],\n",
    ")\n",
    "\n",
    "# ChatAnthropic 모델을 초기화합니다. 온도는 0으로 설정하고, 모델은 \"claude-3-opus-20240229\"를 사용합니다.\n",
    "# model = ChatAnthropic(temperature=0, model=\"claude-3-opus-20240229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 42  # 재현성을 위한 고정된 시드 값\n",
    "\n",
    "### --- 위의 인용된 코드에서 주석과 문서화를 추가함 --- ###\n",
    "\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UMAP을 사용하여 임베딩의 전역 차원 축소를 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원.\n",
    "    - n_neighbors: 선택 사항; 각 점을 고려할 이웃의 수.\n",
    "                   제공되지 않으면 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 지역 차원 축소를 수행합니다. 이는 일반적으로 전역 클러스터링 이후에 사용됩니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원 수.\n",
    "    - num_neighbors: 각 점에 대해 고려할 이웃의 수.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(BIC)을 통해 최적의 클러스터 수를 결정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - max_clusters: 고려할 최대 클러스터 수.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 발견된 최적의 클러스터 수를 나타내는 정수.\n",
    "    \"\"\"\n",
    "    max_clusters = min(\n",
    "        max_clusters, len(embeddings)\n",
    "    )  # 최대 클러스터 수와 임베딩의 길이 중 작은 값을 최대 클러스터 수로 설정\n",
    "    n_clusters = np.arange(1, max_clusters)  # 1부터 최대 클러스터 수까지의 범위를 생성\n",
    "    bics = []  # BIC 점수를 저장할 리스트\n",
    "    for n in n_clusters:  # 각 클러스터 수에 대해 반복\n",
    "        gm = GaussianMixture(\n",
    "            n_components=n, random_state=random_state\n",
    "        )  # 가우시안 혼합 모델 초기화\n",
    "        gm.fit(embeddings)  # 임베딩에 대해 모델 학습\n",
    "        bics.append(gm.bic(embeddings))  # 학습된 모델의 BIC 점수를 리스트에 추가\n",
    "    return n_clusters[np.argmin(bics)]  # BIC 점수가 가장 낮은 클러스터 수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    확률 임계값을 기반으로 가우시안 혼합 모델(GMM)을 사용하여 임베딩을 클러스터링합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - threshold: 임베딩을 클러스터에 할당하기 위한 확률 임계값.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 클러스터 레이블과 결정된 클러스터 수를 포함하는 튜플.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # 최적의 클러스터 수를 구합니다.\n",
    "    # 가우시안 혼합 모델을 초기화합니다.\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)  # 임베딩에 대해 모델을 학습합니다.\n",
    "    probs = gm.predict_proba(\n",
    "        embeddings\n",
    "    )  # 임베딩이 각 클러스터에 속할 확률을 예측합니다.\n",
    "    # 임계값을 초과하는 확률을 가진 클러스터를 레이블로 선택합니다.\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters  # 레이블과 클러스터 수를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 클러스터링, 각 글로벌 클러스터 내에서의 로컬 클러스터링을 순서대로 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩입니다.\n",
    "    - dim: UMAP 축소를 위한 목표 차원입니다.\n",
    "    - threshold: GMM에서 임베딩을 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 각 임베딩의 클러스터 ID를 포함하는 numpy 배열의 리스트입니다.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # 데이터가 충분하지 않을 때 클러스터링을 피합니다.\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # 글로벌 차원 축소\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # 글로벌 클러스터링\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # 각 글로벌 클러스터를 순회하며 로컬 클러스터링 수행\n",
    "    for i in range(n_global_clusters):\n",
    "        # 현재 글로벌 클러스터에 속하는 임베딩 추출\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # 작은 클러스터는 직접 할당으로 처리\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # 로컬 차원 축소 및 클러스터링\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # 로컬 클러스터 ID 할당, 이미 처리된 총 클러스터 수를 조정\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    # 텍스트 문서 목록에 대한 임베딩을 생성합니다.\n",
    "    #\n",
    "    # 이 함수는 `embd` 객체가 존재한다고 가정하며, 이 객체는 텍스트 목록을 받아 그 임베딩을 반환하는 `embed_documents` 메소드를 가지고 있습니다.\n",
    "    #\n",
    "    # 매개변수:\n",
    "    # - texts: List[str], 임베딩할 텍스트 문서의 목록입니다.\n",
    "    #\n",
    "    # 반환값:\n",
    "    # - numpy.ndarray: 주어진 텍스트 문서들에 대한 임베딩 배열입니다.\n",
    "    text_embeddings = embd.embed_documents(\n",
    "        texts\n",
    "    )  # 텍스트 문서들의 임베딩을 생성합니다.\n",
    "    text_embeddings_np = np.array(text_embeddings)  # 임베딩을 numpy 배열로 변환합니다.\n",
    "    return text_embeddings_np  # 임베딩된 numpy 배열을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    텍스트 목록을 임베딩하고 클러스터링하여, 텍스트, 그들의 임베딩, 그리고 클러스터 라벨이 포함된 DataFrame을 반환합니다.\n",
    "\n",
    "    이 함수는 임베딩 생성과 클러스터링을 단일 단계로 결합합니다. 임베딩에 대해 클러스터링을 수행하는 `perform_clustering` 함수의 사전 정의된 존재를 가정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리될 텍스트 문서의 목록입니다.\n",
    "\n",
    "    반환값:\n",
    "    - pandas.DataFrame: 원본 텍스트, 그들의 임베딩, 그리고 할당된 클러스터 라벨이 포함된 DataFrame입니다.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # 임베딩 생성\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # 임베딩에 대해 클러스터링 수행\n",
    "    df = pd.DataFrame()  # 결과를 저장할 DataFrame 초기화\n",
    "    df[\"text\"] = texts  # 원본 텍스트 저장\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # DataFrame에 리스트로 임베딩 저장\n",
    "    df[\"cluster\"] = cluster_labels  # 클러스터 라벨 저장\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    DataFrame에 있는 텍스트 문서를 단일 문자열로 포맷합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - df: 'text' 열에 포맷할 텍스트 문서가 포함된 DataFrame.\n",
    "\n",
    "    반환값:\n",
    "    - 모든 텍스트 문서가 특정 구분자로 결합된 단일 문자열.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()  # 'text' 열의 모든 텍스트를 리스트로 변환\n",
    "    return \"--- --- \\n --- --- \".join(\n",
    "        unique_txt\n",
    "    )  # 텍스트 문서들을 특정 구분자로 결합하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    텍스트 목록에 대해 임베딩, 클러스터링 및 요약을 수행합니다. 이 함수는 먼저 텍스트에 대한 임베딩을 생성하고,\n",
    "    유사성을 기반으로 클러스터링을 수행한 다음, 클러스터 할당을 확장하여 처리를 용이하게 하고 각 클러스터 내의 내용을 요약합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: 처리할 텍스트 문서 목록입니다.\n",
    "    - level: 처리의 깊이나 세부 사항을 정의할 수 있는 정수 매개변수입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 두 개의 데이터프레임을 포함하는 튜플:\n",
    "      1. 첫 번째 데이터프레임(`df_clusters`)은 원본 텍스트, 그들의 임베딩, 그리고 클러스터 할당을 포함합니다.\n",
    "      2. 두 번째 데이터프레임(`df_summary`)은 각 클러스터에 대한 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 텍스트를 임베딩하고 클러스터링하여 'text', 'embd', 'cluster' 열이 있는 데이터프레임을 생성합니다.\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # 클러스터를 쉽게 조작하기 위해 데이터프레임을 확장할 준비를 합니다.\n",
    "    expanded_list = []\n",
    "\n",
    "    # 데이터프레임 항목을 문서-클러스터 쌍으로 확장하여 처리를 간단하게 합니다.\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # 확장된 목록에서 새 데이터프레임을 생성합니다.\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # 처리를 위해 고유한 클러스터 식별자를 검색합니다.\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # 요약\n",
    "    template = \"\"\"여기 LangChain 표현 언어 문서의 하위 집합이 있습니다.\n",
    "    \n",
    "    LangChain 표현 언어는 LangChain에서 체인을 구성하는 방법을 제공합니다.\n",
    "    \n",
    "    제공된 문서의 자세한 요약을 제공하십시오.\n",
    "    \n",
    "    문서:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 각 클러스터 내의 텍스트를 요약을 위해 포맷팅합니다.\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # 요약, 해당 클러스터 및 레벨을 저장할 데이터프레임을 생성합니다.\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    지정된 레벨까지 또는 고유 클러스터의 수가 1이 될 때까지 텍스트를 재귀적으로 임베딩, 클러스터링, 요약하여\n",
    "    각 레벨에서의 결과를 저장합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리할 텍스트들.\n",
    "    - level: int, 현재 재귀 레벨 (1에서 시작).\n",
    "    - n_levels: int, 재귀의 최대 깊이.\n",
    "\n",
    "    반환값:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], 재귀 레벨을 키로 하고 해당 레벨에서의 클러스터 DataFrame과 요약 DataFrame을 포함하는 튜플을 값으로 하는 사전.\n",
    "    \"\"\"\n",
    "    results = {}  # 각 레벨에서의 결과를 저장할 사전\n",
    "\n",
    "    # 현재 레벨에 대해 임베딩, 클러스터링, 요약 수행\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # 현재 레벨의 결과 저장\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # 추가 재귀가 가능하고 의미가 있는지 결정\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # 다음 레벨의 재귀 입력 텍스트로 요약 사용\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # 다음 레벨의 결과를 현재 결과 사전에 병합\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문서의 개수\n",
    "len(docs_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 1 clusters--\n",
      "LangChain 표현 언어(LangChain Expression Language, LCEL)는 LangChain에서 체인을 구성하는 방법을 제공하는 선언적 언어입니다. LCEL은 프로토타입을 코드 변경 없이 바로 프로덕션에 배포할 수 있도록 설계되었습니다. LCEL을 사용하면 간단한 \"프롬프트 + LLM\" 체인부터 수백 단계의 복잡한 체인까지 구성할 수 있습니다. 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **스트리밍 지원**: LCEL로 체인을 구성하면 첫 번째 토큰이 출력될 때까지의 시간을 최소화할 수 있습니다. 예를 들어, LLM에서 스트리밍 출력 파서로 토큰을 스트리밍하여 점진적으로 파싱된 출력을 받을 수 있습니다.\n",
      "\n",
      "2. **비동기 지원**: LCEL로 구성된 체인은 동기 및 비동기 API를 모두 지원합니다. 이는 프로토타입과 프로덕션에서 동일한 코드를 사용할 수 있게 하며, 높은 성능과 동시 요청 처리 능력을 제공합니다.\n",
      "\n",
      "3. **병렬 실행 최적화**: LCEL 체인의 병렬 실행 가능한 단계는 자동으로 병렬 처리되어 지연 시간을 최소화합니다.\n",
      "\n",
      "4. **재시도 및 폴백**: LCEL 체인의 모든 부분에 대해 재시도 및 폴백을 구성할 수 있습니다. 이는 체인의 신뢰성을 높이는 데 유용하며, 스트리밍 지원도 추가될 예정입니다.\n",
      "\n",
      "5. **중간 결과 접근**: 복잡한 체인의 경우 최종 출력이 생성되기 전에 중간 단계의 결과에 접근할 수 있습니다. 이는 사용자에게 진행 상황을 알리거나 디버깅에 유용합니다.\n",
      "\n",
      "6. **입력 및 출력 스키마**: LCEL 체인은 Pydantic 및 JSONSchema 스키마를 통해 입력 및 출력을 검증할 수 있습니다. 이는 LangServe의 중요한 부분입니다.\n",
      "\n",
      "7. **LangSmith 추적 통합**: 체인이 복잡해질수록 각 단계에서 무슨 일이 일어나는지 이해하는 것이 중요합니다. LCEL은 모든 단계를 LangSmith에 자동으로 기록하여 최대한의 가시성과 디버깅 가능성을 제공합니다.\n",
      "\n",
      "8. **LangServe 배포 통합**: LCEL로 생성된 체인은 LangServe를 통해 쉽게 배포할 수 있습니다.\n",
      "\n",
      "LCEL은 체인을 구성하고 관리하는 데 있어 강력한 도구를 제공하며, 프로토타입에서 프로덕션까지의 전환을 원활하게 합니다."
     ]
    }
   ],
   "source": [
    "# 트리 구축\n",
    "leaf_texts = docs_texts  # 문서 텍스트를 리프 텍스트로 설정\n",
    "results = recursive_embed_cluster_summarize(\n",
    "    leaf_texts, level=1, n_levels=3\n",
    ")  # 재귀적으로 임베딩, 클러스터링 및 요약을 수행하여 결과를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# leaf_texts를 복사하여 all_texts를 초기화합니다.\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# 각 레벨의 요약을 추출하여 all_texts에 추가하기 위해 결과를 순회합니다.\n",
    "for level in sorted(results.keys()):\n",
    "    # 현재 레벨의 DataFrame에서 요약을 추출합니다.\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # 현재 레벨의 요약을 all_texts에 추가합니다.\n",
    "    all_texts.extend(summaries)\n",
    "\n",
    "# 이제 all_texts를 사용하여 FAISS vectorstore를 구축합니다.\n",
    "vectorstore = FAISS.from_texts(texts=all_texts, embedding=embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APPROX_TOPK_BUCKETS_B16_D2', 'APPROX_TOPK_BUCKETS_B32_D2', 'APPROX_TOPK_BUCKETS_B8_D2', 'APPROX_TOPK_BUCKETS_B8_D3', 'AdditiveCoarseQuantizer', 'AdditiveQuantizer', 'AlignedTableFloat32', 'AlignedTableUint16', 'AlignedTableUint8', 'AlignedTable_to_array', 'ArrayInvertedLists', 'AutoTuneCriterion', 'BinaryInvertedListScanner', 'BitstringReader', 'BitstringWriter', 'BlockInvertedLists', 'BufferList', 'BufferedIOReader', 'BufferedIOWriter', 'ByteVector', 'ByteVectorVector', 'CMax_float_partition_fuzzy', 'CMax_uint16_partition_fuzzy', 'CMin_float_partition_fuzzy', 'CMin_uint16_partition_fuzzy', 'CenteringTransform', 'CharVector', 'Cloner', 'Clustering', 'Clustering1D', 'ClusteringIterationStats', 'ClusteringIterationStatsVector', 'ClusteringParameters', 'CodePacker', 'CodePackerFlat', 'CodeSet', 'CombinerRangeKNNfloat', 'CombinerRangeKNNint16', 'ComputeCodesAddCentroidsLUT0MemoryPool', 'ComputeCodesAddCentroidsLUT1MemoryPool', 'ConcatenatedInvertedLists', 'DirectMap', 'DirectMapAdd', 'DistanceComputer', 'DoubleVector', 'DummyResultHandler', 'EXACT_TOPK', 'EnumeratedVectors', 'FAISS_VERSION_MAJOR', 'FAISS_VERSION_MINOR', 'FAISS_VERSION_PATCH', 'FastScanStats', 'FileIOReader', 'FileIOWriter', 'FlatCodesDistanceComputer', 'Float32Vector', 'Float32VectorVector', 'Float64Vector', 'FloatVector', 'FloatVectorVector', 'HNSW', 'HNSWStats', 'HStackInvertedLists', 'IDSelector', 'IDSelectorAll', 'IDSelectorAnd', 'IDSelectorArray', 'IDSelectorBatch', 'IDSelectorBitmap', 'IDSelectorNot', 'IDSelectorOr', 'IDSelectorRange', 'IDSelectorTranslated', 'IDSelectorXOr', 'IOReader', 'IOWriter', 'IO_FLAG_MMAP', 'IO_FLAG_ONDISK_SAME_DIR', 'IO_FLAG_READ_ONLY', 'IO_FLAG_SKIP_IVF_DATA', 'IO_FLAG_SKIP_PRECOMPUTE_TABLE', 'ITQMatrix', 'ITQTransform', 'IVFFastScanStats', 'IVFPQSearchParameters', 'IVFSearchParameters', 'IcmEncoder', 'IcmEncoderFactory', 'Index', 'Index2Layer', 'IndexAdditiveQuantizer', 'IndexAdditiveQuantizerFastScan', 'IndexBinary', 'IndexBinaryFlat', 'IndexBinaryFromFloat', 'IndexBinaryHNSW', 'IndexBinaryHash', 'IndexBinaryHashStats', 'IndexBinaryIDMap', 'IndexBinaryIDMap2', 'IndexBinaryIVF', 'IndexBinaryMultiHash', 'IndexBinaryReplicas', 'IndexBinaryShards', 'IndexFastScan', 'IndexFlat', 'IndexFlat1D', 'IndexFlatCodes', 'IndexFlatIP', 'IndexFlatL2', 'IndexHNSW', 'IndexHNSW2Level', 'IndexHNSWFlat', 'IndexHNSWPQ', 'IndexHNSWSQ', 'IndexIDMap', 'IndexIDMap2', 'IndexIVF', 'IndexIVFAdditiveQuantizer', 'IndexIVFAdditiveQuantizerFastScan', 'IndexIVFFastScan', 'IndexIVFFlat', 'IndexIVFFlatDedup', 'IndexIVFIndependentQuantizer', 'IndexIVFInterface', 'IndexIVFLocalSearchQuantizer', 'IndexIVFLocalSearchQuantizerFastScan', 'IndexIVFPQ', 'IndexIVFPQFastScan', 'IndexIVFPQR', 'IndexIVFPQStats', 'IndexIVFProductLocalSearchQuantizer', 'IndexIVFProductLocalSearchQuantizerFastScan', 'IndexIVFProductResidualQuantizer', 'IndexIVFProductResidualQuantizerFastScan', 'IndexIVFResidualQuantizer', 'IndexIVFResidualQuantizerFastScan', 'IndexIVFScalarQuantizer', 'IndexIVFSpectralHash', 'IndexIVFStats', 'IndexLSH', 'IndexLattice', 'IndexLocalSearchQuantizer', 'IndexLocalSearchQuantizerFastScan', 'IndexNNDescent', 'IndexNNDescentFlat', 'IndexNSG', 'IndexNSGFlat', 'IndexNSGPQ', 'IndexNSGSQ', 'IndexPQ', 'IndexPQFastScan', 'IndexPQStats', 'IndexPreTransform', 'IndexProductLocalSearchQuantizer', 'IndexProductLocalSearchQuantizerFastScan', 'IndexProductResidualQuantizer', 'IndexProductResidualQuantizerFastScan', 'IndexProxy', 'IndexRandom', 'IndexRefine', 'IndexRefineFlat', 'IndexRefineSearchParameters', 'IndexReplicas', 'IndexResidual', 'IndexResidualQuantizer', 'IndexResidualQuantizerFastScan', 'IndexRowwiseMinMax', 'IndexRowwiseMinMaxBase', 'IndexRowwiseMinMaxFP16', 'IndexScalarQuantizer', 'IndexShards', 'IndexShardsIVF', 'IndexSplitVectors', 'Int16Vector', 'Int32Vector', 'Int32VectorVector', 'Int64Vector', 'Int64VectorVector', 'Int8Vector', 'IntVector', 'InterruptCallback', 'IntersectionCriterion', 'InvertedListScanner', 'InvertedLists', 'InvertedListsIOHook', 'InvertedListsIterator', 'InvertedListsPtrVector', 'Kmeans', 'LSQTimer', 'LSQTimerScope', 'Level1Quantizer', 'LinearTransform', 'LocalSearchCoarseQuantizer', 'LocalSearchQuantizer', 'LongLongVector', 'LongVector', 'LongVectorVector', 'METRIC_BrayCurtis', 'METRIC_Canberra', 'METRIC_INNER_PRODUCT', 'METRIC_Jaccard', 'METRIC_JensenShannon', 'METRIC_L1', 'METRIC_L2', 'METRIC_Linf', 'METRIC_Lp', 'MapInt64ToInt64', 'MapLong2Long', 'MaskedInvertedLists', 'MatrixStats', 'MultiIndexQuantizer', 'MultiIndexQuantizer2', 'NNDescent', 'NSG', 'NSG_Graph_int', 'Neighbor', 'Nhood', 'NormalizationTransform', 'OPQMatrix', 'OneRecallAtRCriterion', 'OperatingPoint', 'OperatingPointVector', 'OperatingPoints', 'PCAMatrix', 'PQDecoder16', 'PQDecoder8', 'PQDecoderGeneric', 'PQEncoder16', 'PQEncoder8', 'PQEncoderGeneric', 'ParameterRange', 'ParameterRangeVector', 'ParameterSpace', 'PartitionStats', 'PermutationObjective', 'PolysemousTraining', 'ProductAdditiveQuantizer', 'ProductLocalSearchQuantizer', 'ProductQuantizer', 'ProductResidualQuantizer', 'ProgressiveDimClustering', 'ProgressiveDimClusteringParameters', 'ProgressiveDimIndexFactory', 'PyCallbackIDSelector', 'PyCallbackIOReader', 'PyCallbackIOWriter', 'Quantizer', 'RandomGenerator', 'RandomRotationMatrix', 'RangeQueryResult', 'RangeSearchPartialResult', 'RangeSearchResult', 'ReadOnlyInvertedLists', 'RefineBeamLUTMemoryPool', 'RefineBeamMemoryPool', 'RemapDimensionsTransform', 'Repeat', 'RepeatVector', 'Repeats', 'ReproduceDistancesObjective', 'ResidualCoarseQuantizer', 'ResidualQuantizer', 'ResultHeap', 'SHARED_PTR_DISOWN', 'SIMDResultHandler', 'SIMDResultHandlerToFloat', 'ScalarQuantizer', 'SearchParameters', 'SearchParametersHNSW', 'SearchParametersIVF', 'SearchParametersPQ', 'SearchParametersPreTransform', 'SearchParametersResidualCoarseQuantizer', 'SimulatedAnnealingOptimizer', 'SimulatedAnnealingParameters', 'SliceInvertedLists', 'SlidingIndexWindow', 'StopWordsInvertedLists', 'StoreResultHandler', 'SwigPyIterator', 'ThreadedIndexBase', 'ThreadedIndexBaseBinary', 'UInt16Vector', 'UInt32Vector', 'UInt64Vector', 'UInt8Vector', 'UInt8VectorVector', 'Uint64Vector', 'VStackInvertedLists', 'VectorIOReader', 'VectorIOWriter', 'VectorTransform', 'VectorTransformVector', 'Version', 'VisitedTable', 'ZnSphereCodec', 'ZnSphereCodecAlt', 'ZnSphereCodecRec', 'ZnSphereSearch', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_swigfaiss_avx2', 'add_ref_in_constructor', 'add_ref_in_function', 'add_ref_in_method', 'add_ref_in_method_explicit_own', 'add_to_referenced_objects', 'aq_estimate_norm_scale', 'aq_quantize_LUT_and_bias', 'array', 'array_conversions', 'array_to_AlignedTable', 'base_prefix', 'beam_search_encode_step', 'beam_search_encode_step_tab', 'binary_to_real', 'bincode_hist', 'bitvec_print', 'bitvec_shuffle', 'bitvecs2fvecs', 'bucket_sort', 'bvec_checksum', 'bvecs_checksum', 'byte_rand', 'cast_integer_to_float_ptr', 'cast_integer_to_idx_t_ptr', 'cast_integer_to_int_ptr', 'cast_integer_to_uint8_ptr', 'cast_integer_to_void_ptr', 'check_compatible_for_merge', 'check_openmp', 'checksum', 'class_wrappers', 'clone_Quantizer', 'clone_binary_index', 'clone_index', 'compute_PQ_dis_tables_dsub2', 'compute_codes_add_centroids_mp_lut0', 'compute_codes_add_centroids_mp_lut1', 'copy_array_to_AlignedTable', 'copy_array_to_vector', 'crosshamming_count_thres', 'cvar', 'depr_prefix', 'deprecated_name_map', 'deserialize_index', 'deserialize_index_binary', 'downcast_AdditiveQuantizer', 'downcast_IndexBinary', 'downcast_InvertedLists', 'downcast_Quantizer', 'downcast_VectorTransform', 'downcast_index', 'eval_intersection', 'extra_wrappers', 'extract_index_ivf', 'float_maxheap_array_t', 'float_minheap_array_t', 'float_rand', 'float_randn', 'fourcc', 'fourcc_inv', 'fourcc_inv_printable', 'fvec2bitvec', 'fvec_L1', 'fvec_L2sqr', 'fvec_L2sqr_batch_4', 'fvec_L2sqr_by_idx', 'fvec_L2sqr_ny', 'fvec_L2sqr_ny_nearest', 'fvec_L2sqr_ny_nearest_y_transposed', 'fvec_L2sqr_ny_transposed', 'fvec_Linf', 'fvec_add', 'fvec_argsort', 'fvec_argsort_parallel', 'fvec_inner_product', 'fvec_inner_product_batch_4', 'fvec_inner_products_by_idx', 'fvec_inner_products_ny', 'fvec_madd', 'fvec_madd_and_argmin', 'fvec_norm_L2sqr', 'fvec_norms_L2', 'fvec_norms_L2sqr', 'fvec_renorm_L2', 'fvec_sub', 'fvecs2bitvecs', 'fvecs_maybe_subsample', 'generalized_hammings_knn_hc', 'get_compile_options', 'get_cycles', 'get_extra_distance_computer', 'get_invlist_range', 'get_mem_usage_kb', 'get_num_gpus', 'getmillisecs', 'gpu_profiler_start', 'gpu_profiler_stop', 'gpu_sync_all_devices', 'gpu_wrappers', 'hamdis_tab_ham_bytes', 'hamming_count_thres', 'hamming_range_search', 'hammings', 'hammings_knn', 'hammings_knn_hc', 'hammings_knn_mc', 'has_AVX2', 'has_AVX512', 'hash_bytes', 'hashtable_int64_to_int64_add', 'hashtable_int64_to_int64_init', 'hashtable_int64_to_int64_lookup', 'imbalance_factor', 'index_binary_factory', 'index_cpu_to_all_gpus', 'index_cpu_to_gpu_multiple_py', 'index_cpu_to_gpus_list', 'index_factory', 'initialize_IVFPQ_precomputed_table', 'inner_product_to_L2sqr', 'inspect', 'instruction_sets', 'int64_rand', 'int64_rand_max', 'int_maxheap_array_t', 'int_minheap_array_t', 'is_similarity_metric', 'ivec_checksum', 'ivec_hist', 'ivf_residual_add_from_flat_codes', 'ivf_residual_from_quantizer', 'kmax', 'kmeans1d', 'kmeans_clustering', 'kmin', 'knn', 'knn_L2sqr', 'knn_L2sqr_by_idx', 'knn_gpu', 'knn_hamming', 'knn_inner_product', 'knn_inner_products_by_idx', 'lo_build', 'lo_listno', 'lo_offset', 'loaded', 'loader', 'logger', 'logging', 'lrand', 'match_hamming_thres', 'matrix_bucket_sort_inplace', 'matrix_qr', 'memcpy', 'merge_into', 'merge_knn_results', 'merge_knn_results_CMax', 'merge_knn_results_CMin', 'merge_result_table_with', 'normalize_L2', 'np', 'obj', 'omp_get_max_threads', 'omp_set_num_threads', 'opt_env_variable_name', 'opt_level', 'os', 'pack_bitstrings', 'pairwise_L2sqr', 'pairwise_distance_gpu', 'pairwise_distances', 'pairwise_extra_distances', 'pairwise_indexed_L2sqr', 'pairwise_indexed_inner_product', 'platform', 'popcount32', 'popcount64', 'quantize_LUT_and_bias', 'rand', 'rand_perm', 'rand_smooth_vectors', 'randint', 'randn', 'range_search_L2sqr', 'range_search_inner_product', 'range_search_with_parameters', 'range_search_with_parameters_c', 'ranklist_handle_ties', 'ranklist_intersection_size', 'read_InvertedLists', 'read_ProductQuantizer', 'read_VectorTransform', 'read_index', 'read_index_binary', 'real_to_binary', 'refine_beam_LUT_mp', 'refine_beam_mp', 'reflection', 'rev_swig_ptr', 'round_uint8_per_column', 'round_uint8_per_column_multi', 'search_and_return_centroids', 'search_centroid', 'search_with_parameters', 'search_with_parameters_c', 'serialize_index', 'serialize_index_binary', 'set_invlist_range', 'simd16uint16', 'simd_histogram_16', 'simd_histogram_8', 'sizeof_long', 'smawk', 'storage_distance_computer', 'subprocess', 'supported_instruction_sets', 'swig_ptr', 'swigfaiss_avx2', 'symbol', 'sys', 'the_class', 'this_module', 'try_extract_index_ivf', 'unpack_bitstrings', 'vector_float_to_array', 'vector_name_map', 'vector_to_array', 'wait', 'warnings', 'write_InvertedLists', 'write_ProductQuantizer', 'write_VectorTransform', 'write_index', 'write_index_binary']\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# FAISS.load_local 함수 확인\n",
    "print(dir(faiss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 로컬에 FAISS DB 인덱스가 이미 존재하는지 확인하고, 그렇다면 로드하여 vectorstore와 병합한 후 저장합니다.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(DB_INDEX):\n\u001b[1;32m----> 7\u001b[0m     local_index \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDB_INDEX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     local_index\u001b[38;5;241m.\u001b[39mmerge_from(vectorstore)\n\u001b[0;32m      9\u001b[0m     local_index\u001b[38;5;241m.\u001b[39msave_local(DB_INDEX)\n",
      "File \u001b[1;32mc:\\Users\\UserK\\Desktop\\LangChain\\langchain_me\\.conda\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1077\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \n\u001b[0;32m   1065\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[1;32m-> 1077\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1078\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1083\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1084\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1088\u001b[0m     )\n\u001b[0;32m   1089\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "DB_INDEX = \"RAPTOR\"\n",
    "allow_dangerous_deserialization = True\n",
    "# 로컬에 FAISS DB 인덱스가 이미 존재하는지 확인하고, 그렇다면 로드하여 vectorstore와 병합한 후 저장합니다.\n",
    "if os.path.exists(DB_INDEX):\n",
    "    local_index = FAISS.load_local(DB_INDEX, embd)\n",
    "    local_index.merge_from(vectorstore)\n",
    "    local_index.save_local(DB_INDEX)\n",
    "else:\n",
    "    vectorstore.save_local(folder_path=DB_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 문서 포스트 프로세싱\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 문서의 페이지 내용을 이어붙여 반환합니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG 체인 정의\n",
    "rag_chain = (\n",
    "    # 검색 결과를 포맷팅하고 질문을 처리합니다.\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 적용합니다.\n",
    "    | model  # 모델을 적용합니다.\n",
    "    | StrOutputParser()  # 문자열 출력 파서를 적용합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서의 핵심 주제는 LangChain Expression Language (LCEL)입니다. LCEL은 LangChain에서 체인을 구성하는 선언적 언어로, 프로토타입을 코드 변경 없이 바로 프로덕션에 배포할 수 있도록 설계되었습니다. LCEL은 스트리밍 지원, 비동기 지원, 병렬 실행 최적화, 재시도 및 폴백, 중간 결과 접근, 입력 및 출력 스키마 검증, LangSmith 추적 통합, LangServe 배포 통합 등의 기능을 제공합니다."
     ]
    }
   ],
   "source": [
    "_ = rag_chain.invoke(\"전체 문서의 핵심 주제에 대해 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from langchain.output_parsers import PydanticOutputParser\n",
      "from langchain_core.prompts import PromptTemplate\n",
      "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
      "from langchain_openai import OpenAI\n",
      "\n",
      "# Define your desired data structure.\n",
      "class Joke(BaseModel):\n",
      "    setup: str = Field(description=\"question to set up a joke\")\n",
      "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
      "\n",
      "    @validator(\"setup\")\n",
      "    def question_ends_with_question_mark(cls, field):\n",
      "        if field[-1] != \"?\":\n",
      "            raise ValueError(\"Badly formed question!\")\n",
      "        return field\n",
      "\n",
      "# Set up a parser and inject instructions into the prompt template.\n",
      "parser = PydanticOutputParser(pydantic_object=Joke)\n",
      "prompt = PromptTemplate(\n",
      "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
      "    input_variables=[\"query\"],\n",
      "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
      ")\n",
      "\n",
      "# Initialize the model and create a chain.\n",
      "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
      "chain = prompt | model | parser\n",
      "\n",
      "# Invoke the chain with a query.\n",
      "output = chain.invoke({\"query\": \"Tell me a joke.\"})\n",
      "print(output)\n",
      "```\n",
      "This code sets up a PydanticOutputParser to parse a joke structure, integrates it into a prompt template, and uses an OpenAI model to generate and parse a joke."
     ]
    }
   ],
   "source": [
    "_ = rag_chain.invoke(\"PydanticOutputParser 을 활용한 예시 코드를 작성해 주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-querying 방법은 자연어 쿼리를 구조화된 쿼리로 변환하여 벡터 스토어에 적용하는 것입니다. 예시 코드는 다음과 같습니다:\n",
      "\n",
      "```python\n",
      "from langchain_chroma import Chroma\n",
      "from langchain_core.documents import Document\n",
      "from langchain_openai import OpenAIEmbeddings\n",
      "from langchain.chains.query_constructor.base import AttributeInfo\n",
      "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "# 문서 생성\n",
      "docs = [\n",
      "    Document(page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\", metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"}),\n",
      "    Document(page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\", metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2}),\n",
      "    # 추가 문서들...\n",
      "]\n",
      "\n",
      "# 벡터 스토어 생성\n",
      "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())\n",
      "\n",
      "# 메타데이터 필드 정보 설정\n",
      "metadata_field_info = [\n",
      "    AttributeInfo(name=\"genre\", description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\", type=\"string\"),\n",
      "    AttributeInfo(name=\"year\", description=\"The year the movie was released\", type=\"integer\"),\n",
      "    AttributeInfo(name=\"director\", description=\"The name of the movie director\", type=\"string\"),\n",
      "    AttributeInfo(name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"),\n",
      "]\n",
      "\n",
      "# SelfQueryRetriever 생성\n",
      "llm = ChatOpenAI(temperature=0)\n",
      "retriever = SelfQueryRetriever.from_llm(llm, vectorstore, \"Brief summary of a movie\", metadata_field_info)\n",
      "\n",
      "# 쿼리 실행 예시\n",
      "results = retriever.invoke(\"I want to watch a movie rated higher than 8.5\")\n",
      "print(results)\n",
      "```\n",
      "\n",
      "이 코드는 자연어 쿼리를 받아서 해당 조건에 맞는 문서를 반환합니다."
     ]
    }
   ],
   "source": [
    "_ = rag_chain.invoke(\"self-querying 방법과 예시 코드를 작성해 주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
