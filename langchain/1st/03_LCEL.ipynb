{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[API KEY]\n",
      "sk-None-FZcW7iODyxjiAh7qYSpIT3BlbkFJyqnfN***************\n",
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "01_Basic\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_teddynote import logging\n",
    "print(load_dotenv())\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)\n",
    "logging.langsmith(\"01_Basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 어디인가요?\n",
      "미국의 수도는 어디인가요?\n"
     ]
    }
   ],
   "source": [
    "for i in ['대한민국','미국']:\n",
    "  prompt = prompt_template.format(country = i)\n",
    "  print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해 쉽게 설명해주세요.')\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "- python 딕셔너리 형태로 입력값을 전달\n",
    "- invoke()함수 호출 시, 입력값을 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고, 이를 바탕으로 새로운 데이터에 대한 예측을 만들어내는 과정입니다. \\n\\n일반적으로 인공지능 모델은 학습 데이터를 이용하여 가중치와 편향을 조정하며 학습을 진행합니다. 학습 데이터는 입력 데이터와 그에 대한 정답 레이블로 구성되어 있고, 모델은 입력 데이터를 받아들여서 예측을 만들고, 이 예측값과 정답 레이블을 비교하여 오차를 계산하고 이를 최소화하는 방향으로 가중치와 편향을 조정해가며 학습을 진행합니다.\\n\\n이러한 과정을 반복하면서 모델은 데이터의 패턴을 학습하게 되고, 학습이 충분히 이루어지면 새로운 데이터에 대해 정확한 예측을 할 수 있게 됩니다. 이렇게 학습된 모델은 실제 응용 분야에서 다양한 작업을 수행할 수 있게 되며, 인공지능 기술의 발전에 큰 역할을 합니다.', response_metadata={'token_usage': {'completion_tokens': 362, 'prompt_tokens': 33, 'total_tokens': 395}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d9bbf271-1ad7-4db4-bb1d-5951e0311547-0', usage_metadata={'input_tokens': 33, 'output_tokens': 362, 'total_tokens': 395})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {'topic':'인공지능 모델의 학습 원리'}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스트리밍 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고 이를 분석하여 패턴이나 규칙을 학습하는 과정입니다. 모델은 초기에는 랜덤한 가중치와 편향을 가지고 있어서 정확한 예측을 할 수 없지만, 학습을 통해 이를 조정해나가면서 성능을 향상시킵니다.\n",
      "\n",
      "주어진 데이터를 이용해 예측을 수행하고, 예측 결과와 실제 결과를 비교하여 오차를 계산합니다. 이 오차를 최소화하기 위해 모델의 가중치와 편향을 조정하면서 학습을 진행합니다. 이러한 과정을 반복하면서 모델이 데이터에 대해 더 잘 이해하고 정확한 예측을 하게 됩니다.\n",
      "\n",
      "즉, 인공지능 모델의 학습 원리는 데이터를 통해 패턴을 학습하고 오차를 최소화하는 과정을 반복하는 것이라고 할 수 있습니다."
     ]
    }
   ],
   "source": [
    "answer = chain.stream(input)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain에 출력파서를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain= prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고 그 데이터를 분석하여 패턴을 찾아내는 과정입니다. 이 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용하여 이루어집니다.\\n\\n먼저, 입력층에는 데이터가 입력되고, 각각의 입력은 가중치와 곱해져 은닉층으로 전달됩니다. 은닉층은 여러 층으로 구성되어 있고, 각각의 뉴런은 입력된 데이터를 처리하고 결과를 출력층으로 전달합니다. 출력층은 최종 결과를 출력하며, 이 결과는 모델이 예측한 값입니다.\\n\\n이때, 모델은 입력된 데이터와 실제 결과값을 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 학습을 진행합니다. 이를 위해 모델은 가중치를 조정하고, 다양한 데이터를 학습하여 패턴을 더 잘 인식할 수 있도록 학습을 반복합니다.\\n\\n이러한 과정을 통해 인공지능 모델은 주어진 데이터를 분석하고 패턴을 학습하여 새로운 데이터에 대해 예측을 수행할 수 있습니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 이를 분석하고 패턴을 찾아내는 과정입니다. 모델은 입력 데이터를 기반으로 가중치와 편향을 조절하여 최적의 결과를 출력할 수 있도록 학습을 진행합니다. \n",
      "\n",
      "이 과정은 주어진 데이터를 사용하여 모델이 예측한 값과 실제 값 사이의 차이를 최소화하는 방향으로 이루어집니다. 이를 위해 모델은 손실 함수를 사용하여 예측 값과 실제 값 사이의 오차를 계산하고, 이 오차를 최소화하는 방향으로 가중치와 편향을 업데이트합니다. \n",
      "\n",
      "이렇게 반복적으로 학습을 진행하면 모델은 주어진 데이터에 대해 정확한 예측을 할 수 있는 능력을 향상시키게 됩니다. 이러한 과정을 통해 인공지능 모델은 주어진 문제를 해결하고 새로운 데이터에 대해 예측을 수행할 수 있는 능력을 갖추는 것입니다."
     ]
    }
   ],
   "source": [
    "answer = chain.stream(input)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 템플릿으리 변경하여 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 \n",
    "맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고해 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model_name = 'gpt-4-turbo')\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  Server: Hi there, welcome! Can I get you started with something to drink?\n",
      "  Customer: Yes, I'll have a glass of water, please.\n",
      "  Server: Sure thing. Are you ready to order, or do you need a few more minutes?\n",
      "  Customer: I think I'm ready to order. I'll have the grilled salmon with a side of vegetables, please.\n",
      "  Server: Excellent choice! How would you like your salmon cooked?\n",
      "  Customer: Medium, please.\n",
      "  Server: Perfect. Anything else I can get for you right now?\n",
      "  Customer: No, that's all for now, thank you.\n",
      "  Server: Great, I'll get your order right in. Enjoy your meal!\n",
      "\n",
      "- 한글 해석:\n",
      "  서버: 안녕하세요, 어서 오세요! 음료로 무엇을 시작해 드릴까요?\n",
      "  손님: 네, 물 한 잔 주세요.\n",
      "  서버: 알겠습니다. 주문하실 준비가 되셨나요, 아니면 조금 더 시간이 필요하신가요?\n",
      "  손님: 주문할 준비가 된 것 같아요. 구운 연어와 야채 사이드를 주세요.\n",
      "  서버: 훌륭한 선택이세요! 연어는 어떻게 조리해 드릴까요?\n",
      "  손님: 중간 정도로 해주세요.\n",
      "  서버: 완법합니다. 지금 당장 더 필요한 것 있으세요?\n",
      "  손님: 아니요, 지금은 이게 다에요, 감사합니다.\n",
      "  서버: 좋습니다, 주문을 바로 드리겠습니다. 식사 맛있게 하세요!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  A: Hello! I'd like to order a pizza for delivery.\n",
      "  B: Sure, what type of pizza would you like?\n",
      "  A: I'd like a large pepperoni pizza with extra cheese, please.\n",
      "  B: Anything else to add?\n",
      "  A: Yes, can I also have a side of garlic bread and a Coke?\n",
      "  B: Absolutely. Can I have your address, please?\n",
      "  A: It's 452 Park Avenue, Apartment 21B.\n",
      "  B: Great, your total comes to $24.50. It should take about 30-45 minutes for the delivery. Is that okay?\n",
      "  A: That's perfect, thank you!\n",
      "\n",
      "- 한글 해석:\n",
      "  A: 안녕하세요! 배달로 피자 하나 주문하고 싶어요.\n",
      "  B: 네, 어떤 피자를 드릴까요?\n",
      "  A: 큰 사이즈의 페퍼로니 피자에 치즈를 추가로 더 해주세요.\n",
      "  B: 추가로 더 필요한 것이 있으신가요?\n",
      "  A: 네, 갈릭 브레드와 콜라도 하나 주세요.\n",
      "  B: 알겠습니다. 주소를 알려주시겠어요?\n",
      "  A: 452 파크 애비뉴, 아파트 21B입니다.\n",
      "  B: 좋습니다, 총 금액은 $24.50이고, 배달까지 대략 30-45분 정도 소요됩니다. 괜찮으신가요?\n",
      "  A: 네, 감사합니다!"
     ]
    }
   ],
   "source": [
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
